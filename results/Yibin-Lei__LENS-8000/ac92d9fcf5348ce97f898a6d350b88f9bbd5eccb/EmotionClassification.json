{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 24.2205913066864,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.9186500000000001,
        "f1": 0.8830096162438135,
        "f1_weighted": 0.920659899919408,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.9186500000000001,
        "scores_per_experiment": [
          {
            "accuracy": 0.9215,
            "f1": 0.8826383505194184,
            "f1_weighted": 0.923112026589592
          },
          {
            "accuracy": 0.922,
            "f1": 0.8858869140113078,
            "f1_weighted": 0.9234152876898872
          },
          {
            "accuracy": 0.9135,
            "f1": 0.8797120624038163,
            "f1_weighted": 0.9156674124199986
          },
          {
            "accuracy": 0.9175,
            "f1": 0.8821483592391859,
            "f1_weighted": 0.9199479483856216
          },
          {
            "accuracy": 0.9185,
            "f1": 0.8846587933681089,
            "f1_weighted": 0.9204676774352061
          },
          {
            "accuracy": 0.9245,
            "f1": 0.8897510275662871,
            "f1_weighted": 0.9256923915267254
          },
          {
            "accuracy": 0.913,
            "f1": 0.8765429436866548,
            "f1_weighted": 0.9156097142411226
          },
          {
            "accuracy": 0.9135,
            "f1": 0.8789826391494934,
            "f1_weighted": 0.9168406941365927
          },
          {
            "accuracy": 0.92,
            "f1": 0.8827524131588566,
            "f1_weighted": 0.9214892311857104
          },
          {
            "accuracy": 0.9225,
            "f1": 0.8870226593350058,
            "f1_weighted": 0.9243566155836231
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}